# -*- coding: utf-8 -*-
"""Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

import pandas as pd

wine_df = pd.read_csv("/content/winequality-red.csv")

wine_df.head()

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as ex
import warnings
warnings.filterwarnings('ignore')
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc

wine_df['pH'].values

wine_df.info()

wine_df.describe()

wine_df['quality'].value_counts()

corr = wine_df.corr()

sns.heatmap(corr, cmap = 'coolwarm');

plt.figure(figsize=(10, 6))
sns.set(style="whitegrid")
ax = sns.barplot(x="quality", y="alcohol", data=wine_df)
plt.title("Most Positive Relationship", fontsize=16)
ax.set_xlabel("quality", fontsize=12)
ax.set_ylabel("alcohol", fontsize=12)
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 6))
sns.set(style="whitegrid")
ax = sns.barplot(x="quality", y="volatile acidity", data=wine_df)
plt.title("Most Negative Relationship", fontsize=16)
ax.set_xlabel("quality", fontsize=12)
ax.set_ylabel("volatile acidity", fontsize=12)
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 6))

# Create line plots for 'alcohol' and 'residual sugar' against 'density'
sns.lineplot(x="alcohol", y="density", data=wine_df, label='alcohol', marker='o')
sns.lineplot(x="residual sugar", y="density", data=wine_df, label='residual Sugar', marker='s')

plt.title("Density vs. Alcohol and Residual Sugar", fontsize=16)
plt.xlabel("Density", fontsize=12)
plt.ylabel("Value", fontsize=12)
plt.legend()
plt.tight_layout()
plt.show()

# Set the style and create a pairplot
sns.set(style="ticks")
sns.pairplot(wine_df, diag_kind="kde", markers="o", hue="quality")

plt.suptitle("Pairplot of Wine Data", y=1.02, fontsize=16)
plt.show()

# Create a 4x3 grid of subplots
fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(20, 20))

# Modify the color list to match the number of columns in your dataset
colors = ['#491D8B', '#6929C4', '#8A3FFC', '#A56EFF',
          '#7D3AC1', '#AF4BCE', '#DB4CB2', '#EB548C',
          '#EC96E0', '#A2128E', '#E8D9F3', '#641811']

# Loop through each column in your wine_df dataset
for index, column in enumerate(wine_df.columns):
    if index < 12:  # Limit the iteration to the number of subplots
        ax = axes.flatten()[index]
        ax.hist(wine_df[column], color=colors[index], label=column)
        ax.legend(loc="best")

plt.suptitle("Histograms", size=20)
plt.tight_layout()
plt.show()

wine_df.isnull().sum()

# Check for duplicates across all columns
duplicated = wine_df.duplicated()

# Print the number of duplicated instances
print("Number of duplicated instances:", duplicated.sum())

# Print the duplicated instances
wine_df[duplicated]

wine_df = wine_df.drop_duplicates()

duplicated   = wine_df.duplicated()
print("number of duplicated instances: ", duplicated.sum())
wine_df[duplicated]

wine_df["quality"] = np.where(wine_df["quality"] >= 7 , 1, 0)
wine_df['quality'].value_counts()

X = wine_df.drop('quality', axis = 1)
y = wine_df['quality']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)

sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

fig = ex.pie(y_train, names='quality')
fig.update_layout(title='<b>Qualtiy Proportion before SMOTE Upsampling<b>')
fig.show()

# transform the dataset
oversample = SMOTE()
X_train, y_train = oversample.fit_resample(X_train, y_train)
print(pd.Series(y_train).value_counts())

fig = ex.pie(y_train, names='quality')
fig.update_layout(title='<b>Qualtiy Proportion after SMOTE Upsampling<b>')
fig.show()

# Create a Decision Tree classifier
dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_train, y_train)
y_pred = dt.predict(X_test)

# Evaluate the model's accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

# Display a classification report for more detailed metrics
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

# Specify the cross-validation strategy
cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
scores = cross_val_score(dt, X, y, cv=cv, scoring='accuracy')  # You can choose a different scoring metric
print("Cross-validation scores:", scores)

# Calculate and print the mean and standard deviation of the scores
mean_score = scores.mean()
std_score = scores.std()
print(f"Mean accuracy: {mean_score:.2f}")
print(f"Standard deviation: {std_score:.2f}")

# Calculate ROC curve and AUC score
fpr, tpr, _ = roc_curve(y_test, dt.predict_proba(X_test)[:, 1])
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.show()

# Create a Random Forest classifier
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)

# Evaluate the model's accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

# Display a classification report for more detailed metrics
report = classification_report(y_test, y_pred)
print("Classification Report:")
print(report)

# Calculate ROC curve and AUC score
fpr, tpr, _ = roc_curve(y_test, rf.predict_proba(X_test)[:, 1])
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.show()

# Get feature importances
feature_importance = rf.feature_importances_
feature_names = X.columns

# Sort features by importance
sorted_idx = feature_importance.argsort()

# Create a horizontal bar plot
plt.figure(figsize=(10, 6))
plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')
plt.yticks(range(len(sorted_idx)), [feature_names[i] for i in sorted_idx])
plt.xlabel('Feature Importance')
plt.title('Feature Importance of Decision Tree Model')
plt.show()

from sklearn.model_selection import GridSearchCV
# Define a grid of hyperparameters to search
param_grid = {
    'n_estimators': [50, 100, 150, 200],
    'max_depth': [None, 10, 20, 30]
}

# Create a GridSearchCV object
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

# Print the best parameters and the corresponding accuracy
print("Best Parameters:", grid_search.best_params_)
print("Best Accuracy:", grid_search.best_score_)